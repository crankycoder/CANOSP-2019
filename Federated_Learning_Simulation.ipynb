{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OsHSQ1TEXDNZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "from mozfldp.simulation_util import client_update\n",
    "import warnings\n",
    "\n",
    "# hide the warning message temporarily\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# auto-reload the modules everytime a cell is run\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RfZrf09ZofuP"
   },
   "source": [
    "## Client Update Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "fZj9flYHXNd4",
    "outputId": "09beecb0-cd45-46d6-9932-77cef46d5044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[28.48672566,  0.        ,  0.        ]]), array([-9.])]\n"
     ]
    }
   ],
   "source": [
    "# this data will be provided by the server\n",
    "features = [[1, 4, 3], [0, 2, 2], [1, 4, 0], [0, 5, 3], [1, 2, 1], [0, 2, 9]]\n",
    "labels = [1, 0, 1, 0, 1, 0]\n",
    "\n",
    "coefs = np.array([29., 0., 0.]) # should be of size num_classes * num_features\n",
    "intercepts = np.array([-9])\n",
    "weights = [coefs, intercepts]\n",
    "\n",
    "epochs = 3\n",
    "batch_size = 3\n",
    "\n",
    "new_weights = client_update(weights, epochs, batch_size, features, labels)\n",
    "print(new_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server Update Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Weights:  [[ 0.80400241 -3.12282041 -3.92707568]] [-8.0286598]\n",
      "Updated Weights:  [[-7.28915493 -3.03298239 -1.92202299]] [40.74921299]\n",
      "Updated Weights:  [[-2.45964505  2.7924037  -1.22915393]] [25.20736215]\n",
      "Updated Weights:  [[13.6692742   1.48275331 -1.84787059]] [-9.19809708]\n",
      "Updated Weights:  [[-4.91304623  8.41655083  4.96001876]] [-0.88102296]\n",
      "Updated Weights:  [[ 6.52044623 -3.09614447  0.01755993]] [19.97969872]\n",
      "Updated Weights:  [[  6.22102608   3.24009844 -10.68396063]] [-19.16314781]\n",
      "Updated Weights:  [[ 3.0790037  -2.42007241  2.84207234]] [19.33979612]\n",
      "Updated Weights:  [[-6.99879558  3.1977462   5.9107004 ]] [13.83269944]\n",
      "Updated Weights:  [[0.98751793 4.26986506 6.28814264]] [5.99900549]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mozfldp.simulation_util import server_update\n",
    "\n",
    "init_weights = [np.array([0, 0, 0]), np.array([0])]\n",
    "client_fraction = 0.5\n",
    "num_rounds = 10\n",
    "epoch = 10\n",
    "batch_size = 25\n",
    "display_weight_per_round = True\n",
    "\n",
    "num_client = 100\n",
    "samples_per_client = 100\n",
    "num_features = 3\n",
    "features = np.random.randint(10, size=(num_client, samples_per_client, num_features))\n",
    "labels = np.random.randint(2, size=(num_client, samples_per_client))\n",
    "\n",
    "new_clf = server_update(init_weights, client_fraction, num_rounds, features, labels, epoch, batch_size, display_weight_per_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Params:  {'batch_size': 40, 'client_fraction': 1, 'epoch': 1, 'init_weight': [array([[0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.]]), array([0., 0., 0.])], 'num_rounds': 10}\n",
      "Weights: [array([[ 16.34326005,  -0.50580066,  30.56774855,  -4.35001733],\n",
      "       [ 10.85435969,  21.46259506,   4.04081311, -12.78816112],\n",
      "       [-13.84453399,  27.72390721,   4.06205591, -11.13830017]]), array([-202.26483295, -223.30841626, -214.60556442])]\n",
      "Score: 0.342000\n",
      "\n",
      "\n",
      "Training...\n",
      "Params:  {'batch_size': 40, 'client_fraction': 1, 'epoch': 5, 'init_weight': [array([[0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.]]), array([0., 0., 0.])], 'num_rounds': 10}\n",
      "Weights: [array([[  3.179614  ,   1.99292087,  32.9183223 ,  -9.58484057],\n",
      "       [  6.30625111,  16.53126575,   3.2083592 ,  -8.19112142],\n",
      "       [-17.55541852,  22.99300796,  -1.90997027,  -4.803823  ]]), array([-209.62041684, -218.74500102, -217.03806768])]\n",
      "Score: 0.340750\n",
      "\n",
      "\n",
      "Training...\n",
      "Params:  {'batch_size': 40, 'client_fraction': 0.1, 'epoch': 1, 'init_weight': [array([[0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.]]), array([0., 0., 0.])], 'num_rounds': 10}\n",
      "Weights: [array([[  6.49705181, -34.54798548,  54.97254156,  30.79272825],\n",
      "       [ 19.87540962,   0.94731083,  36.32193608,  -3.30227443],\n",
      "       [-15.24630026,  68.64377398, -64.41005376, -14.00669705]]), array([-129.15674506, -233.73755879, -253.56054086])]\n",
      "Score: 0.336625\n",
      "\n",
      "\n",
      "Training...\n",
      "Params:  {'batch_size': 40, 'client_fraction': 0.1, 'epoch': 5, 'init_weight': [array([[0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.]]), array([0., 0., 0.])], 'num_rounds': 10}\n",
      "Weights: [array([[ 11.11385246,   6.78701789,  21.4274086 ,  -9.91928463],\n",
      "       [ 21.11629778,  35.97460806,  -8.15107508, -28.23051995],\n",
      "       [ -5.77334876,   7.90325742,  14.56303517,  45.92817363]]), array([-211.96457471, -220.40735302, -221.5820079 ])]\n",
      "Score: 0.334500\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid, train_test_split\n",
    "from mozfldp.simulation_util import server_update\n",
    "import numpy as np\n",
    "import mozfldp.random_data_gen as rdata_gen\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "NUM_SAMPLES = 20000\n",
    "NUM_LABELS = 3\n",
    "NUM_FEATURES = 4\n",
    "NUM_CLIENTS = 100\n",
    "g_prms = rdata_gen.InputGenParams(NUM_SAMPLES, NUM_LABELS, NUM_FEATURES, NUM_CLIENTS)\n",
    "df = pd.read_csv(\"datasets/blob_S20000_L3_F4_U100.csv\")\n",
    "\n",
    "sim_labels, sim_features = rdata_gen.transform_data_for_simulator_format(df, g_prms)\n",
    "features = np.array(sim_features)\n",
    "labels = np.array(sim_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=0)\n",
    "\n",
    "init_weights = np.zeros((NUM_LABELS, NUM_FEATURES), dtype=np.float64, order=\"C\")\n",
    "init_intercept = np.zeros(NUM_LABELS, dtype=np.float64, order=\"C\")\n",
    "\n",
    "# Find all the permutations of the parameters\n",
    "param_grid = {\"client_fraction\": [1, 0.1],\n",
    "              \"epoch\": [1, 5],\n",
    "              \"batch_size\": [40], # TODO: need to implement an infinite batch size\n",
    "              \"init_weight\": [[init_weights, init_intercept]],\n",
    "              \"num_rounds\": [10]}\n",
    "\n",
    "# run training/testing over all parameter combinations to get the best combination\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(\"Training...\")\n",
    "    print(\"Params: \", params)\n",
    "    classifier = server_update(params[\"init_weight\"], params[\"client_fraction\"], params[\"num_rounds\"], X_train, y_train, params[\"epoch\"], params[\"batch_size\"], False)\n",
    "    weights = [classifier.coef_, classifier.intercept_]\n",
    "\n",
    "    # need to remove the client dimension from our data for testing \n",
    "    # ex: [[[1, 1], [2, 2]], [[3, 3], [4, 4]]] needs to become [[1, 1], [2, 2], [3, 3], [4, 4]] for features \n",
    "    # and [[1, 2], [3, 4]] needs to become [1, 2, 3, 4] for labels \n",
    "    reshaped_X_test = np.reshape(X_test, (X_test.shape[0] * X_test.shape[1], X_test.shape[2]))\n",
    "    reshaped_y_test = np.reshape(y_test, y_test.size)\n",
    "    \n",
    "    score = classifier.score(reshaped_X_test, reshaped_y_test)\n",
    "\n",
    "    print('Weights: {}\\nScore: {:f}\\n\\n'.format(weights, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Federated Learning Simulation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
